{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statistics\n",
    "import itertools\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplify_dir = '/Volumes/Data2/RST/notebook/GTFS/TTC_2016-10-03/GIS Simplify/'\n",
    "gtfs_dir = '/Volumes/Data2/RST/notebook/GTFS/TTC_2016-10-03/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify_dir = 'D:/RST/RST/notebook/GTFS/TTC_2016-10-03/GIS Simplify/'\n",
    "\n",
    "# gtfs_dir = 'D:/RST/notebook/GTFS/TTC_2016-10-03/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ward_df = gpd.read_file('/Volumes/Data2/RST/notebook/GIS/wards_no-island.geojson')\n",
    "\n",
    "ward_df = ward_df[['AREA_SHORT_CODE', 'geometry']]\n",
    "ward_df = ward_df.to_crs('epsg:26917')\n",
    "ward_df['area'] = ward_df['geometry'].area/1000000\n",
    "\n",
    "ward_df = ward_df.rename(columns = {'AREA_SHORT_CODE':'ward'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ward_int = pd.read_csv('/Volumes/Data2/RST/notebook/GIS/int_wards.csv')\n",
    "\n",
    "#ward_int = pd.read_csv('D:/RST/notebook/GIS/int_wards.csv')\n",
    "\n",
    "ward_int['INT_ID_STR'] = ward_int['INT_ID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(row):\n",
    "\n",
    "    single_cycle = row.copy()\n",
    "    single_cycle.append(single_cycle[0])\n",
    "    single_cycle.append(None)\n",
    "\n",
    "\n",
    "    cycle_pairs = list(zip(single_cycle [::1], single_cycle [1::1]))[:-1]\n",
    "    cycle_pairs = [list(map(int, sublist)) for sublist in cycle_pairs]\n",
    "    cycle_df = route_dir.merge(pd.DataFrame.from_records(cycle_pairs, columns = ['INT_ID_o', 'INT_ID_d']))\n",
    "\n",
    "    first_route = cycle_df.iloc[0,2]\n",
    "\n",
    "    #check for cycles where it can be traversed by 1 route, ie eliminate out and back trips\n",
    "    for route in first_route:\n",
    "        if len(cycle_df[cycle_df['route_short_name'].apply(lambda x: route in x)]) == len(cycle_df):\n",
    "            return ward,0,0,1\n",
    "            break\n",
    "        else:\n",
    "            return ward, 1, cycle_df['scaled_freq'].min(), 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ward 1, Size 92 Found 1 cycles\n",
      "Ward 2, Size 40 Found 0 cycles\n",
      "Ward 3, Size 67 Found 0 cycles\n",
      "Ward 4, Size 49 Found 0 cycles\n",
      "Ward 5, Size 83 Found 1 cycles\n",
      "Ward 6, Size 56 Found 0 cycles\n",
      "Ward 7, Size 36 Found 0 cycles\n",
      "Ward 8, Size 40 Found 0 cycles\n",
      "Ward 9, Size 41 Found 0 cycles\n",
      "Ward 10, Size 27 Found 0 cycles\n",
      "Ward 11, Size 24 Found 0 cycles\n",
      "Ward 12, Size 17 Found 0 cycles\n",
      "Ward 13, Size 37 Found 1 cycles\n",
      "Ward 14, Size 61 Found 1 cycles\n",
      "Ward 15, Size 28 Found 0 cycles\n",
      "Ward 16, Size 36 Found 0 cycles\n",
      "Ward 17, Size 43 Found 0 cycles\n",
      "Ward 18, Size 39 Found 0 cycles\n",
      "Ward 19, Size 20 Found 0 cycles\n",
      "Ward 20, Size 32 Found 0 cycles\n",
      "Ward 21, Size 39 Found 0 cycles\n",
      "Ward 22, Size 51 Found 1 cycles\n",
      "Ward 23, Size 49 Found 1 cycles\n",
      "Ward 24, Size 32 Found 0 cycles\n",
      "Ward 25, Size 34 Found 0 cycles\n",
      "Ward 1, Size 171 Found 22 cycles\n",
      "Ward 2, Size 151 Found 6 cycles\n",
      "Ward 3, Size 163 Found 8 cycles\n",
      "Ward 4, Size 91 Found 9 cycles\n",
      "Ward 5, Size 162 Found 14 cycles\n",
      "Ward 6, Size 118 Found 9 cycles\n",
      "Ward 7, Size 111 Found 5 cycles\n",
      "Ward 8, Size 122 Found 6 cycles\n",
      "Ward 9, Size 87 Found 6 cycles\n",
      "Ward 10, Size 54 Found 4 cycles\n",
      "Ward 11, Size 79 Found 10 cycles\n",
      "Ward 12, Size 57 Found 3 cycles\n",
      "Ward 13, Size 61 Found 7 cycles\n",
      "Ward 14, Size 115 Found 8 cycles\n",
      "Ward 15, Size 96 Found 2 cycles\n",
      "Ward 16, Size 76 Found 7 cycles\n",
      "Ward 17, Size 91 Found 9 cycles\n",
      "Ward 18, Size 85 Found 4 cycles\n",
      "Ward 19, Size 100 Found 5 cycles\n",
      "Ward 20, Size 127 Found 2 cycles\n",
      "Ward 21, Size 118 Found 11 cycles\n",
      "Ward 22, Size 102 Found 15 cycles\n",
      "Ward 23, Size 109 Found 11 cycles\n",
      "Ward 24, Size 60 Found 4 cycles\n",
      "Ward 25, Size 101 Found 0 cycles\n",
      "Ward 1, Size 169 Found 21 cycles\n",
      "Ward 2, Size 150 Found 5 cycles\n",
      "Ward 3, Size 157 Found 8 cycles\n",
      "Ward 4, Size 89 Found 8 cycles\n",
      "Ward 5, Size 159 Found 11 cycles\n",
      "Ward 6, Size 114 Found 6 cycles\n",
      "Ward 7, Size 95 Found 5 cycles\n",
      "Ward 8, Size 120 Found 5 cycles\n",
      "Ward 9, Size 87 Found 6 cycles\n",
      "Ward 10, Size 51 Found 3 cycles\n",
      "Ward 11, Size 74 Found 7 cycles\n",
      "Ward 12, Size 54 Found 1 cycles\n",
      "Ward 13, Size 58 Found 4 cycles\n",
      "Ward 14, Size 115 Found 8 cycles\n",
      "Ward 15, Size 96 Found 2 cycles\n",
      "Ward 16, Size 74 Found 5 cycles\n",
      "Ward 17, Size 91 Found 8 cycles\n",
      "Ward 18, Size 83 Found 3 cycles\n",
      "Ward 19, Size 99 Found 5 cycles\n",
      "Ward 20, Size 127 Found 2 cycles\n",
      "Ward 21, Size 111 Found 4 cycles\n",
      "Ward 22, Size 99 Found 12 cycles\n",
      "Ward 23, Size 110 Found 11 cycles\n",
      "Ward 24, Size 59 Found 3 cycles\n",
      "Ward 25, Size 101 Found 0 cycles\n",
      "Ward 1, Size 170 Found 22 cycles\n",
      "Ward 2, Size 151 Found 6 cycles\n",
      "Ward 3, Size 160 Found 8 cycles\n",
      "Ward 4, Size 91 Found 9 cycles\n",
      "Ward 5, Size 162 Found 14 cycles\n",
      "Ward 6, Size 118 Found 9 cycles\n",
      "Ward 7, Size 114 Found 6 cycles\n",
      "Ward 8, Size 122 Found 6 cycles\n",
      "Ward 9, Size 87 Found 6 cycles\n",
      "Ward 10, Size 54 Found 4 cycles\n",
      "Ward 11, Size 79 Found 10 cycles\n",
      "Ward 12, Size 57 Found 3 cycles\n",
      "Ward 13, Size 58 Found 4 cycles\n",
      "Ward 14, Size 115 Found 8 cycles\n",
      "Ward 15, Size 96 Found 2 cycles\n",
      "Ward 16, Size 75 Found 6 cycles\n",
      "Ward 17, Size 91 Found 9 cycles\n",
      "Ward 18, Size 85 Found 4 cycles\n",
      "Ward 19, Size 101 Found 5 cycles\n",
      "Ward 20, Size 127 Found 2 cycles\n",
      "Ward 21, Size 117 Found 10 cycles\n",
      "Ward 22, Size 102 Found 15 cycles\n",
      "Ward 23, Size 111 Found 11 cycles\n",
      "Ward 24, Size 60 Found 4 cycles\n",
      "Ward 25, Size 98 Found 0 cycles\n",
      "Ward 1, Size 152 Found 14 cycles\n",
      "Ward 2, Size 151 Found 6 cycles\n",
      "Ward 3, Size 154 Found 6 cycles\n",
      "Ward 4, Size 89 Found 8 cycles\n",
      "Ward 5, Size 159 Found 11 cycles\n",
      "Ward 6, Size 103 Found 2 cycles\n",
      "Ward 7, Size 95 Found 4 cycles\n",
      "Ward 8, Size 120 Found 5 cycles\n",
      "Ward 9, Size 87 Found 6 cycles\n",
      "Ward 10, Size 50 Found 3 cycles\n",
      "Ward 11, Size 73 Found 7 cycles\n",
      "Ward 12, Size 54 Found 1 cycles\n",
      "Ward 13, Size 58 Found 4 cycles\n",
      "Ward 14, Size 115 Found 8 cycles\n",
      "Ward 15, Size 96 Found 2 cycles\n",
      "Ward 16, Size 74 Found 5 cycles\n",
      "Ward 17, Size 91 Found 8 cycles\n",
      "Ward 18, Size 83 Found 3 cycles\n",
      "Ward 19, Size 99 Found 5 cycles\n",
      "Ward 20, Size 127 Found 2 cycles\n",
      "Ward 21, Size 111 Found 4 cycles\n",
      "Ward 22, Size 99 Found 12 cycles\n",
      "Ward 23, Size 109 Found 11 cycles\n",
      "Ward 24, Size 59 Found 3 cycles\n",
      "Ward 25, Size 96 Found 0 cycles\n"
     ]
    }
   ],
   "source": [
    "period_list = [['EM', 4], ['AM', 7], ['MD', 11], ['PM', 17], ['EV', 20]]\n",
    "\n",
    "for i in period_list:\n",
    "    period_hr = i[1]\n",
    "    period = i[0]\n",
    "\n",
    "    G = nx.read_gexf('/Volumes/Data2/RST/notebook/networks/' + period +'-RM-16.gexf')\n",
    "    graph_data = pd.read_csv('/Volumes/Data2/RST/notebook/networks/' + period +'-RM-16.csv')\n",
    "\n",
    "\n",
    "\n",
    "    stop_times_od = pd.read_csv(gtfs_dir + 'stop_times_full.csv')\n",
    "\n",
    "    route_dir = stop_times_od[stop_times_od['hr_o'] == period_hr]\n",
    "    route_dir = route_dir[['INT_ID_o', 'INT_ID_d', 'route_short_name']].drop_duplicates()\n",
    "\n",
    "    route_dir = route_dir.append(route_dir.rename(columns = {'INT_ID_o':'INT_ID_d', 'INT_ID_d':'INT_ID_o'})[['INT_ID_o', \n",
    "                                                                                'INT_ID_d', 'route_short_name']])\n",
    "\n",
    "    route_dir = route_dir.drop_duplicates()\n",
    "\n",
    "\n",
    "    route_dir = route_dir.groupby(['INT_ID_o', 'INT_ID_d'])['route_short_name'].apply(list).reset_index()\n",
    "    route_dir = route_dir.merge(graph_data)\n",
    "\n",
    "    result_list = []\n",
    "    ward_n = []\n",
    "\n",
    "    for ward in range(1,26,1):\n",
    "\n",
    "        G_ward = G.copy()\n",
    "\n",
    "\n",
    "        G_ward.remove_nodes_from(list(ward_int[ward_int['AREA_SHORT_CODE'] != ward]['INT_ID_STR']))\n",
    "\n",
    "        N = G_ward.size()\n",
    "\n",
    "        #find cycles\n",
    "        cycle_list = list(nx.cycle_basis(G_ward))\n",
    "        print('Ward ' + str(ward) + ', Size ' + str(N) + ' Found '+ str(len(cycle_list)) + ' cycles')\n",
    "\n",
    "        temp_list = list(map(func, cycle_list))\n",
    "\n",
    "\n",
    "        result_list.append(temp_list)\n",
    "\n",
    "        if len(cycle_list) == 0:\n",
    "            result_list.append([(ward, 0, 0, 0)])\n",
    "\n",
    "        ward_n.append([ward, N])\n",
    "\n",
    "    combined = list(itertools.chain.from_iterable(result_list))\n",
    "    result_df = pd.DataFrame.from_records(\n",
    "        combined, columns = ['ward', 'cycles', 'scaled_cycles', 'removed_cycles']).groupby(\n",
    "        'ward').sum().reset_index()\n",
    "    result_df = result_df.merge(pd.DataFrame.from_records(ward_n, columns = ['ward', 'N']))\n",
    "\n",
    "    result_df['cycle_availability'] = result_df['scaled_cycles']/(2 * result_df['N'] + 5)\n",
    "    result_df = result_df.merge(ward_df[['ward', 'area']])\n",
    "\n",
    "    result_df = result_df.merge(ward_int[['AREA_NAME', 'AREA_SHORT_CODE']].drop_duplicates(), left_on = ['ward'], \n",
    "                     right_on = ['AREA_SHORT_CODE']).rename(columns = {'AREA_NAME':'ward_name'}).drop(\n",
    "        columns = ['AREA_SHORT_CODE'])\n",
    "    result_df['cycle_density'] = result_df['scaled_cycles']/result_df['area']\n",
    "\n",
    "\n",
    "    result_df.to_csv('cycles-' + period + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
